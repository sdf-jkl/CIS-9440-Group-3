{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-storage-blob # Microoft Azure\n",
    "!pip install pyarrow\n",
    "!pip install psycopg2 sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from math import ceil\n",
    "import datetime\n",
    "import calendar\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON configuration file\n",
    "config_file_path = 'config.json'\n",
    "\n",
    "# Load the JSON configuration file\n",
    "with open(config_file_path, 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Print the configuration\n",
    "#Connection_STRING = config[\"connectionString\"]\n",
    "\n",
    "CONNECTION_STRING_AZURE_STORAGE = config[\"connectionString\"]\n",
    "CONTAINER_AZURE = ''\n",
    "\n",
    "# Initialize the BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING_AZURE_STORAGE)\n",
    "\n",
    "# Get the container client\n",
    "container_client = blob_service_client.get_container_client(CONTAINER_AZURE)\n",
    "\n",
    "pwd = ''\n",
    "database_url = f''\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(database_url)\n",
    "\n",
    "blob_list = container_client.list_blobs()\n",
    "\n",
    "for blob in blob_list:\n",
    "    print(\"Processing blob:\", blob.name)\n",
    "    blob_client = container_client.get_blob_client(blob=blob.name)\n",
    "    blob_data = blob_client.download_blob()\n",
    "    blob_content = blob_data.readall().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(blob_content))\n",
    "    print(\"Successfully extract\",blob.name)\n",
    "    # Append the DataFrame to the PostgreSQL table\n",
    "    df.to_sql(\"\",schema=\"\", con=engine, if_exists='append', index=False)\n",
    "    print(\"Successfully load\",blob.name,\"to DW\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
